{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "Load packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling ParallelExp [34d6aced-5efe-466f-b6da-e4bb150683a7]\n",
      "└ @ Base loading.jl:1260\n"
     ]
    }
   ],
   "source": [
    "# Initialize workers\n",
    "num_of_procs = 10 # You can also use addprocs() with no argument to create as many workers as your threads\n",
    "using Distributed\n",
    "addprocs(num_of_procs, exeflags=\"--project\") # initial workers with the project env in current work directory\n",
    "\n",
    "@everywhere push!(LOAD_PATH, \"..\")\n",
    "using ParallelExp\n",
    "\n",
    "# POMCPOW\n",
    "@everywhere using POMCPOW\n",
    "using BasicPOMCP\n",
    "\n",
    "# LB-DESPOT\n",
    "@everywhere push!(LOAD_PATH, \"../../LB-DESPOT\")\n",
    "@everywhere using LBDESPOT # LBDESPOT pkg\n",
    "\n",
    "# UCT-DESPOT\n",
    "@everywhere push!(LOAD_PATH, \"../../UCT-DESPOT\")\n",
    "@everywhere using UCTDESPOT # UCT-DESPOT pkg\n",
    "\n",
    "# QMDP\n",
    "using QMDP\n",
    "\n",
    "# POMDP related pkgs\n",
    "@everywhere using POMDPs # Basic POMDP framework\n",
    "@everywhere using POMDPSimulators # For parallel simulator\n",
    "using POMDPPolicies # For function policy and random policy\n",
    "@everywhere using ParticleFilters # For simple particle filter\n",
    "using BeliefUpdaters # For roomba and BabyPOMDP belief updater\n",
    "\n",
    "# For visualization\n",
    "using D3Trees\n",
    "using POMDPModelTools\n",
    "using POMDPGifs\n",
    "import Cairo,Fontconfig\n",
    "\n",
    "# For data processing and storing\n",
    "using Statistics\n",
    "using DataFrames\n",
    "using CSV\n",
    "using Random\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VDPTag2 Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCT-DESPOT\n",
    "@everywhere push!(LOAD_PATH, \"../../VDPTag2.jl\")\n",
    "@everywhere using VDPTag2\n",
    "using Plots\n",
    "using Reel\n",
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VDPTag2 Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp = VDPTagPOMDP()\n",
    "\n",
    "# For POMCPOW\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "value_estimator = FORollout(ToNextML(pomdp))\n",
    "pomcpow_dict = Dict(:default_action=>[RandomPolicy(pomdp),],\n",
    "                    :estimate_value=>[random_value_estimator],\n",
    "                    :tree_queries=>[200000,], \n",
    "                    :max_time=>[1.0,], \n",
    "                    :criterion=>[MaxUCB(30.),])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [POMCPOWSolver=>pomcpow_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VDPTag2 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = POMCPOWSolver(tree_queries=200000, max_time=1.0, criterion=MaxUCB(30), estimate_value=random_value_estimator)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# hr = HistoryRecorder(max_steps=30)\n",
    "# belief_updater = SIRParticleFilter(pomdp, 2000)\n",
    "# hist = POMDPs.simulate(hr, pomdp, planner, belief_updater)\n",
    "\n",
    "# frames = Frames(MIME(\"image/png\"), fps=2)\n",
    "# gr()\n",
    "# @showprogress \"Creating gif...\" for i in 1:n_steps(hist)\n",
    "#     push!(frames, plot(pomdp, view(hist, 1:i)))\n",
    "# end\n",
    "\n",
    "# filename = string(\"VDPTag2.gif\")\n",
    "# write(filename, frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = POMCPOWSolver(tree_queries=200000,\n",
    "                        max_time=1.0,\n",
    "                        criterion=MaxUCB(30),\n",
    "                        k_action=1,\n",
    "                        alpha_action=0.2,\n",
    "                        k_observation=1,\n",
    "                        alpha_observation=0.2,\n",
    "                        estimate_value=value_estimator,\n",
    "                        tree_in_info=true)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "b0 = initialstate_distribution(pomdp)\n",
    "a, info = action_info(planner, b0)\n",
    "D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on VDPTag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 100\n",
    "max_steps = 100\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "CSV.write(\"VDPTag2_POMCPOW.csv\", dfs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete VDPTag2 Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp = AODiscreteVDPTagPOMDP()\n",
    "\n",
    "# To-do\n",
    "# Transplant ManageUncertainty policy\n",
    "\n",
    "# For LB-DESPOT\n",
    "random_bounds = IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp)), 100.0, check_terminal=true)\n",
    "lbdespot_dict = Dict(:default_action=>[RandomPolicy(pomdp),], \n",
    "                    :bounds=>[random_bounds],\n",
    "                    :K=>[500, 300],\n",
    "                    :beta=>[0.5, 0., 0.1, 1., 5.])\n",
    "\n",
    "# For UCT-DESPOT\n",
    "random_rollout_policy = RandomPolicy(pomdp)\n",
    "uctdespot_dict = Dict(:default_action=>[RandomPolicy(pomdp),],\n",
    "                    :rollout_policy=>[random_rollout_policy],\n",
    "                    :max_trials=>[100000,],\n",
    "                    :K=>[500, 1000],\n",
    "                    :m=>[10, 30],\n",
    "                    :c=>[10.,])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [LB_DESPOTSolver=>lbdespot_dict, \n",
    "                UCT_DESPOTSolver=>uctdespot_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete VDPTag2 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=random_bounds, beta=0.5, K=100, default_action=RandomPolicy(pomdp))\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=random_rollout_policy, max_trials=100000, m=10, K=500, c=10)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# hr = HistoryRecorder(max_steps=30)\n",
    "# belief_updater = SIRParticleFilter(pomdp, 2000)\n",
    "# hist = POMDPs.simulate(hr, pomdp, planner, belief_updater)\n",
    "\n",
    "# frames = Frames(MIME(\"image/png\"), fps=2)\n",
    "# gr()\n",
    "# @showprogress \"Creating gif...\" for i in 1:n_steps(hist)\n",
    "#     push!(frames, plot(pomdp, view(hist, 1:i)))\n",
    "# end\n",
    "\n",
    "# filename = string(\"Discrete_VDPTag2.gif\")\n",
    "# write(filename, frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=random_bounds, beta=0.0, K=100, default_action=RandomPolicy(pomdp), tree_in_info=true)\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=random_rollout_policy, max_trials=100000, m=10, K=500, c=10, tree_in_info=true)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# b0 = initialstate(pomdp)\n",
    "# a, info = action_info(planner, b0)\n",
    "# println(\"number of trials: $(info[:record][1])\")\n",
    "# println(\"time for building DESPOT: $(info[:record][2])\")\n",
    "# D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on Discrete VDPTag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 100\n",
    "max_steps = 100\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "CSV.write(\"DiscreteVDPTag2_LB-DESPOT.csv\", dfs[1])\n",
    "CSV.write(\"DiscreteVDPTag2_UCT-DESPOT.csv\", dfs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RockSample Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Pair{DataType,Dict{Symbol,Array{T,1} where T}},1}:\n",
       " UCT_DESPOTSolver => Dict(:m => [50, 100],:default_action => RandomPolicy{Random._GLOBAL_RNG,RockSamplePOMDP{9},NothingUpdater}[RandomPolicy{Random._GLOBAL_RNG,RockSamplePOMDP{9},NothingUpdater}(Random._GLOBAL_RNG(), RockSamplePOMDP{9}\n",
       "  map_size: Tuple{Int64,Int64}\n",
       "  rocks_positions: StaticArrays.SArray{Tuple{9},StaticArrays.SArray{Tuple{2},Int64,1,2},1,9}\n",
       "  init_pos: StaticArrays.SArray{Tuple{2},Int64,1,2}\n",
       "  sensor_efficiency: Float64 20.0\n",
       "  bad_rock_penalty: Float64 -10.0\n",
       "  good_rock_reward: Float64 20.0\n",
       "  exit_reward: Float64 10.0\n",
       "  terminal_state: RSState{9}\n",
       "  discount_factor: Float64 0.95\n",
       ", NothingUpdater())],:max_trials => [100000],:K => [1000, 2000],:c => [1.0, 10.0],:rollout_policy => RandomPolicy{Random._GLOBAL_RNG,RockSamplePOMDP{9},NothingUpdater}[RandomPolicy{Random._GLOBAL_RNG,RockSamplePOMDP{9},NothingUpdater}(Random._GLOBAL_RNG(), RockSamplePOMDP{9}\n",
       "  map_size: Tuple{Int64,Int64}\n",
       "  rocks_positions: StaticArrays.SArray{Tuple{9},StaticArrays.SArray{Tuple{2},Int64,1,2},1,9}\n",
       "  init_pos: StaticArrays.SArray{Tuple{2},Int64,1,2}\n",
       "  sensor_efficiency: Float64 20.0\n",
       "  bad_rock_penalty: Float64 -10.0\n",
       "  good_rock_reward: Float64 20.0\n",
       "  exit_reward: Float64 10.0\n",
       "  terminal_state: RSState{9}\n",
       "  discount_factor: Float64 0.95\n",
       ", NothingUpdater())])\n",
       " UCT_DESPOTSolver => Dict(:m => [50, 30],:default_action => RandomPolicy{Random._GLOBAL_RNG,RockSamplePOMDP{9},NothingUpdater}[RandomPolicy{Random._GLOBAL_RNG,RockSamplePOMDP{9},NothingUpdater}(Random._GLOBAL_RNG(), RockSamplePOMDP{9}\n",
       "  map_size: Tuple{Int64,Int64}\n",
       "  rocks_positions: StaticArrays.SArray{Tuple{9},StaticArrays.SArray{Tuple{2},Int64,1,2},1,9}\n",
       "  init_pos: StaticArrays.SArray{Tuple{2},Int64,1,2}\n",
       "  sensor_efficiency: Float64 20.0\n",
       "  bad_rock_penalty: Float64 -10.0\n",
       "  good_rock_reward: Float64 20.0\n",
       "  exit_reward: Float64 10.0\n",
       "  terminal_state: RSState{9}\n",
       "  discount_factor: Float64 0.95\n",
       ", NothingUpdater())],:max_trials => [100000],:K => [300, 100, 500],:c => [1.0, 10.0],:rollout_policy => RandomPolicy{Random._GLOBAL_RNG,RockSamplePOMDP{9},NothingUpdater}[RandomPolicy{Random._GLOBAL_RNG,RockSamplePOMDP{9},NothingUpdater}(Random._GLOBAL_RNG(), RockSamplePOMDP{9}\n",
       "  map_size: Tuple{Int64,Int64}\n",
       "  rocks_positions: StaticArrays.SArray{Tuple{9},StaticArrays.SArray{Tuple{2},Int64,1,2},1,9}\n",
       "  init_pos: StaticArrays.SArray{Tuple{2},Int64,1,2}\n",
       "  sensor_efficiency: Float64 20.0\n",
       "  bad_rock_penalty: Float64 -10.0\n",
       "  good_rock_reward: Float64 20.0\n",
       "  exit_reward: Float64 10.0\n",
       "  terminal_state: RSState{9}\n",
       "  discount_factor: Float64 0.95\n",
       ", NothingUpdater())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@everywhere using RockSample\n",
    "pomdp = RockSamplePOMDP(map_size=(7,8),\n",
    "                        rocks_positions=[(2,3), (1,8), (4,5), (5,2), (7,7)], \n",
    "                        sensor_efficiency=20.0,\n",
    "                        discount_factor=0.95, \n",
    "                        good_rock_reward = 20.0)\n",
    "\n",
    "pomdp = RockSamplePOMDP(map_size=(11,11),\n",
    "                        rocks_positions=[(2,8), (1,6), (4,9), (5,2), (8,7), (9,10), (11,2)], \n",
    "                        sensor_efficiency=20.0,\n",
    "                        discount_factor=0.95, \n",
    "                        good_rock_reward = 20.0)\n",
    "\n",
    "pomdp = RockSamplePOMDP(map_size=(15,15),\n",
    "                        rocks_positions=[(2,3), (1,12), (4,1), (5,5), (8,15), (9,14), (12,1), (14,15), (15,7)], \n",
    "                        sensor_efficiency=20.0,\n",
    "                        discount_factor=0.95, \n",
    "                        good_rock_reward = 20.0)\n",
    "\n",
    "# For LB-DESPOT\n",
    "random_bounds = IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp)), 30.0, check_terminal=true)\n",
    "lbdespot_dict = Dict(:default_action=>[RandomPolicy(pomdp),], \n",
    "                    :bounds=>[random_bounds],\n",
    "                    :K=>[300, 100],\n",
    "                    :beta=>[0.5, 0., 0.1, 1., 5.])\n",
    "\n",
    "# For UCT-DESPOT\n",
    "random_rollout_policy = RandomPolicy(pomdp)\n",
    "uctdespot_dict1 = Dict(:default_action=>[RandomPolicy(pomdp),],\n",
    "                    :rollout_policy=>[random_rollout_policy],\n",
    "                    :max_trials=>[100000,],\n",
    "                    :K=>[1000, 2000],\n",
    "                    :m=>[50, 100],\n",
    "                    :c=>[1, 10.])\n",
    "uctdespot_dict2 = Dict(:default_action=>[RandomPolicy(pomdp),],\n",
    "                    :rollout_policy=>[random_rollout_policy],\n",
    "                    :max_trials=>[100000,],\n",
    "                    :K=>[300, 100, 500],\n",
    "                    :m=>[50, 30],\n",
    "                    :c=>[1.,10,])\n",
    "# For POMCPOW\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "pomcpow_dict = Dict(:default_action=>[RandomPolicy(pomdp),],\n",
    "                    :estimate_value=>[random_value_estimator],\n",
    "                    :tree_queries=>[200000,], \n",
    "                    :max_time=>[1.0,], \n",
    "                    :criterion=>[MaxUCB(10.),])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [#LB_DESPOTSolver=>lbdespot_dict, \n",
    "                UCT_DESPOTSolver=>uctdespot_dict1,\n",
    "                UCT_DESPOTSolver=>uctdespot_dict2,] \n",
    "                #POMCPOWSolver=>pomcpow_dict,\n",
    "                #QMDPSolver=>Dict(:max_iterations=>[200,])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RockSample Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=random_bounds, beta=0.5, K=100, default_action=RandomPolicy(pomdp))\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=random_rollout_policy, max_trials=100000, m=10, K=500, c=10)\n",
    "# solver = POMCPOWSolver(tree_queries=200000, max_time=1.0, criterion=MaxUCB(30), estimate_value=random_value_estimator)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# makegif(pomdp, planner, filename=\"rock_sample.gif\", max_steps=100, show_progress=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=random_bounds, beta=0.0, K=100, default_action=RandomPolicy(pomdp), tree_in_info=true)\n",
    "solver = UCT_DESPOTSolver(rollout_policy=random_rollout_policy, max_trials=100000, m=50, K=1000, c=1, tree_in_info=true)\n",
    "# solver = POMCPOWSolver(tree_queries=200000, max_time=1.0, criterion=MaxUCB(10), estimate_value=random_value_estimator, tree_in_info=true)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "b0 = initialstate_distribution(pomdp)\n",
    "a, info = action_info(planner, b0)\n",
    "# println(\"number of trials: $(info[:record][1])\")\n",
    "# println(\"time for building DESPOT: $(info[:record][2])\")\n",
    "D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on RockSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating experimental design\n",
      "Simulations begin\n",
      "Preparing simulators for the 1-th set of parameters of the LB_DESPOTSolver\n",
      "Solving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSimulating...100%|██████████████████████████████████████| Time: 0:14:07\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"RockSample_LB-DESPOT.csv\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_episodes = 100\n",
    "max_steps = 100\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=true)\n",
    "\n",
    "# CSV.write(\"RockSample_LB-DESPOT.csv\", dfs[1])\n",
    "CSV.write(\"RockSample_UCT-DESPOT.csv\", dfs[1])\n",
    "# CSV.write(\"RockSample_POMCPOW.csv\", dfs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BabyPOMDP Setting\n",
    "Setting up a BabyPOMDP problem for further using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using POMDPModels # For BabyPOMDP\n",
    "pomdp = BabyPOMDP(-5, -10, 0.1, 0.8, 0.1, 0.95) # defualt setting except that the discount is 0.95\n",
    "\n",
    "# Feed When Crying Policy\n",
    "@everywhere function feed_when_crying(b)\n",
    "    if typeof(b) == Bool\n",
    "        b \n",
    "    elseif (typeof(b) <: UCTDESPOT.ScenarioBelief || typeof(b) <: LBDESPOT.ScenarioBelief)\n",
    "        if typeof(currentobs(b)) <: Bool\n",
    "            currentobs(b)\n",
    "        else\n",
    "            pdf(currentobs(b), true) > 0.5\n",
    "        end\n",
    "    elseif typeof(b) <: POMDPModels.BoolDistribution\n",
    "        rand(b)\n",
    "    else\n",
    "        pdf(b, true) > 0.5\n",
    "    end\n",
    "end\n",
    "feed_when_crying_policy = solve(FunctionSolver(feed_when_crying), pomdp)\n",
    "\n",
    "# For LB-DESPOT\n",
    "# Assume all following rewards are coming from the worst case, \"hungry but don't feed\"\n",
    "@everywhere fval(m::BabyPOMDP, x) = reward(m, true, false)/(1-discount(m))\n",
    "bounds = IndependentBounds(DefaultPolicyLB(feed_when_crying_policy, final_value=fval), 0.0)\n",
    "random_bounds = IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp), final_value=fval), 0.0)\n",
    "lbdespot_dict = Dict(:default_action=>[feed_when_crying_policy,], \n",
    "                    :bounds=>[bounds, random_bounds],\n",
    "                    :K=>[1000, 2000, 3600, 5000],\n",
    "                    :beta=>[0., 0.1, 0.5, 1., 5.])\n",
    "\n",
    "# For UCT-DESPOT\n",
    "rollout_policy = feed_when_crying_policy\n",
    "random_rollout_policy = RandomPolicy(pomdp)\n",
    "uctdespot_dict = Dict(:rollout_policy=>[rollout_policy, random_rollout_policy],\n",
    "                        :K=>[1000, 2000, 3600, 5000],\n",
    "                        :m=>[30, 60, 100],\n",
    "                        :c=>[500., 1000., 2000.])\n",
    "\n",
    "# For POMCPOW\n",
    "value_estimator = PORollout(feed_when_crying_policy, PreviousObservationUpdater())\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "pomcpow_dict = Dict(:estimate_value=>[value_estimator, random_value_estimator],\n",
    "                    :tree_queries=>[200000,], \n",
    "                    :max_time=>[1.0,], \n",
    "                    :criterion=>[MaxUCB(0.1), MaxUCB(1.0), MaxUCB(10.), MaxUCB(100.), MaxUCB(1000.)])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [LB_DESPOTSolver=>lbdespot_dict, \n",
    "                UCT_DESPOTSolver=>uctdespot_dict, \n",
    "                POMCPOWSolver=>pomcpow_dict,\n",
    "                QMDPSolver=>Dict(:max_iterations=>[200,]),\n",
    "                FuncSolver=>Dict(:func=>[feed_when_crying,])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BabyPOMDP Visualization\n",
    "Visualize BabyPOMDP in form of a tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solver = LB_DESPOTSolver(bounds=bounds, beta=0.0, K=3000, default_action=feed_when_crying_policy, tree_in_info=true)\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=rollout_policy, m=1, K=1000, c=1000, tree_in_info=true)\n",
    "# solver = POMCPOWSolver(tree_queries=200000, max_time=1.0, criterion=MaxUCB(1), estimate_value=value_estimator, tree_in_info=true)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "b0 = initialstate_distribution(pomdp)\n",
    "a, info = action_info(planner, b0)\n",
    "# println(\"number of trials: $(info[:record][1])\")\n",
    "# println(\"time for building DESPOT: $(info[:record][2])\")\n",
    "# println(\"tree depth: $(info[:record][3])\")\n",
    "D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on BabyPOMDP\n",
    "First, run a simulation of one episode and one max step in case there's some latent bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_episodes = 1\n",
    "max_steps = 1\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "# CSV.write(\"LaserTag_LB-DESPOT.csv\", dfs[1])\n",
    "CSV.write(\"LaserTag_UCT-DESPOT.csv\", dfs[2])\n",
    "# CSV.write(\"LaserTag_POMCPOW.csv\", dfs[3])\n",
    "# CSV.write(\"LaserTag_QMDP.csv\", dfs[4])\n",
    "# CSV.write(\"LaserTag_Move_Towards.csv\", dfs[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaserTag Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using LaserTag\n",
    "pomdp = gen_lasertag()\n",
    "belief_updater = SIRParticleFilter(pomdp, 10000)\n",
    "\n",
    "# Policies\n",
    "@everywhere function move_towards(b)\n",
    "    if typeof(b) <: LaserTag.LTInitialBelief\n",
    "        return rand(1:9)\n",
    "    elseif typeof(b) <: LBDESPOT.ScenarioBelief || \n",
    "        typeof(b) <: UCTDESPOT.ScenarioBelief || \n",
    "        typeof(b) <: ParticleFilters.ParticleCollection\n",
    "        \n",
    "        s = rand(b)\n",
    "    else\n",
    "        s = b\n",
    "    end\n",
    "    # try to sneak up diagonally\n",
    "    diff = s.opponent-s.robot\n",
    "    dx = diff[1]\n",
    "    dy = diff[2]\n",
    "    if abs(dx) == 1 && abs(dy) == 1\n",
    "        LaserTag.DIR_TO_ACTION[[dx, dy]]\n",
    "    elseif abs(dx) == 1\n",
    "        LaserTag.DIR_TO_ACTION[[0, sign(dy)]]\n",
    "    elseif abs(dy) == 1\n",
    "        LaserTag.DIR_TO_ACTION[[sign(dx), 0]]\n",
    "    else\n",
    "        LaserTag.DIR_TO_ACTION[[sign(dx), sign(dy)]]\n",
    "    end\n",
    "end\n",
    "move_towards_policy = solve(FunctionSolver(move_towards), pomdp)\n",
    "\n",
    "# For LB-DESPOT\n",
    "bounds = IndependentBounds(DefaultPolicyLB(move_towards_policy), 10.0, check_terminal=true)\n",
    "random_bounds = IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp)), 10.0, check_terminal=true)\n",
    "lbdespot_dict = Dict(:default_action=>[move_towards_policy,],\n",
    "                    :bounds=>[bounds, random_bounds],\n",
    "                    :K=>[1000, 3000],\n",
    "                    :lambda=>[0.1, 0.0],\n",
    "                    :beta=>[0., 0.5,])\n",
    "\n",
    "# For UCT-DESPOT\n",
    "rollout_policy = move_towards_policy\n",
    "random_rollout_policy = RandomPolicy(pomdp)\n",
    "uctdespot_dict = Dict(:default_action=>[move_towards_policy,],\n",
    "                        :rollout_policy=>[rollout_policy, random_rollout_policy],\n",
    "                        :K=>[3000, 5000],\n",
    "                        :m=>[100, 1],\n",
    "                        :c=>[100.,])\n",
    "\n",
    "# For POMCPOW\n",
    "value_estimator = FORollout(move_towards_policy)\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "pomcpow_dict = Dict(:estimate_value=>[value_estimator, random_value_estimator],\n",
    "                    :tree_queries=>[150000,], \n",
    "                    :max_time=>[1.0,], \n",
    "                    :criterion=>[MaxUCB(100),],\n",
    "                    :enable_action_pw=>[false,],\n",
    "                    :k_observation=>[2.,],\n",
    "                    :alpha_observation=>[0.15,])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [LB_DESPOTSolver=>lbdespot_dict, \n",
    "                UCT_DESPOTSolver=>uctdespot_dict, \n",
    "                POMCPOWSolver=>pomcpow_dict,\n",
    "                QMDPSolver=>Dict(:max_iterations=>[200,]),\n",
    "                FuncSolver=>Dict(:func=>[move_towards,])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaserTag Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=bounds, beta=0.5, K=5000, lambda=0.1, tree_in_info=true)\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=rollout_policy, m=10, K=5000, c=100, tree_in_info=true)\n",
    "solver = POMCPOWSolver(tree_queries=1000000,\n",
    "                        max_time=1.0,\n",
    "                        criterion=MaxUCB(100),\n",
    "                        estimate_value=value_estimator,\n",
    "                        enable_action_pw=false,\n",
    "                        k_observation=2,\n",
    "                        alpha_observation=0.15,\n",
    "                        tree_in_info=true)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "b0 = initialstate_distribution(pomdp)\n",
    "@time a, info = action_info(planner, b0)\n",
    "# println(\"number of trials: $(first(info[:record]))\")\n",
    "# println(\"time for building DESPOT: $(last(info[:record]))\")\n",
    "D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on LaserTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 100\n",
    "max_steps = 100\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          belief_updater=belief_updater,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "# CSV.write(\"LaserTag_LB-DESPOT.csv\", dfs[1])\n",
    "CSV.write(\"LaserTag_UCT-DESPOT.csv\", dfs[1])\n",
    "CSV.write(\"LaserTag_POMCPOW.csv\", dfs[2])\n",
    "CSV.write(\"LaserTag_QMDP.csv\", dfs[3])\n",
    "CSV.write(\"LaserTag_Move_Towards.csv\", dfs[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roomba Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roomba related pkgs\n",
    "# Roomba need ParticleFilters = \"0.2\" for compatibility\n",
    "@everywhere push!(LOAD_PATH, \"../../Roomba\")\n",
    "@everywhere using Roomba # For Roomba Env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bumper Roomba Setting\n",
    "Setting up a Roomba problem with bumper sensor for further using.\\\n",
    "The parameters of Roomba are listed as follows.\n",
    "```\n",
    "maximum velocity of Roomba [m/s]\n",
    "v_max::Float64  = 10.0  # m/s\n",
    "\n",
    "maximum turn-rate of Roombda [rad/s]\n",
    "om_max::Float64 = 1.0   # rad/s\n",
    "\n",
    "simulation time-step [s]\n",
    "dt::Float64     = 0.5   # s\n",
    "\n",
    "penalty for wall-contact\n",
    "contact_pen::Float64 = -1.0 \n",
    "\n",
    "penalty per time-step\n",
    "time_pen::Float64 = -0.1\n",
    "\n",
    "reward for reaching goal\n",
    "goal_reward::Float64 = 10\n",
    "\n",
    "penalty for reaching stairs\n",
    "stairs_penalty::Float64 = -10\n",
    "\n",
    "specifies room configuration (location of stairs/goal) {1,2,3}\n",
    "config::Int = 1\n",
    "\n",
    "environment room struct\n",
    "room::Room  = Room(sspace,configuration=config)\n",
    "\n",
    "environment state-space (ContinuousRoombaStateSpace or DiscreteRoombaStateSpace)\n",
    "sspace::SS = ContinuousRoombaStateSpace()\n",
    "\n",
    "environment action-space struct\n",
    "aspace::AS = RoombaActions()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_speed = 2.0\n",
    "speed_interval = 2.0\n",
    "max_turn_rate = 1.0\n",
    "turn_rate_interval = 1.0\n",
    "\n",
    "sensor = Bumper()\n",
    "num_particles = 5000 # number of particles in belief\n",
    "\n",
    "pos_noise_coeff = 0.3\n",
    "ori_noise_coeff = 0.1\n",
    "\n",
    "# POMDP problem\n",
    "action_space = vec([RoombaAct(v, om) for v in 0:speed_interval:max_speed, om in -max_turn_rate:turn_rate_interval:max_turn_rate])\n",
    "pomdp = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(aspace=action_space));\n",
    "\n",
    "# Belief updater\n",
    "resampler = BumperResampler(num_particles, pomdp, pos_noise_coeff, ori_noise_coeff)\n",
    "belief_updater = BasicParticleFilter(pomdp, resampler, num_particles)\n",
    "\n",
    "# Rush Policy\n",
    "rush_policy = FunctionPolicy() do b\n",
    "    if !(typeof(b) <: ParticleFilters.ParticleCollection) &&\n",
    "        !(typeof(b) <: Roomba.RoombaInitialDistribution) &&\n",
    "        b !== nothing &&\n",
    "        typeof(b) == Bool ? b : (typeof(currentobs(b)) == Bool ? currentobs(b) : false)\n",
    "\n",
    "        [max_speed, max_turn_rate]\n",
    "    else\n",
    "        [max_speed, 0.0]\n",
    "    end\n",
    "end\n",
    "\n",
    "# For LB-DESPOT\n",
    "bounds = IndependentBounds(DefaultPolicyLB(rush_policy), 10.0, check_terminal=true)\n",
    "random_bounds = IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp)), 10.0, check_terminal=true)\n",
    "lbdespot_dict = Dict(:default_action=>[rush_policy,], \n",
    "                    :bounds=>[bounds, random_bounds],\n",
    "                    :K=>[100, 300, 500],\n",
    "                    :beta=>[0., 0.1, 1., 10., 100.])\n",
    "\n",
    "# For UCT-DESPOT\n",
    "rollout_policy = rush_policy\n",
    "random_rollout_policy = RandomPolicy(pomdp)\n",
    "uctdespot_dict = Dict(:rollout_policy=>[rollout_policy, random_rollout_policy],\n",
    "                        :K=>[100, 300, 500],\n",
    "                        :m=>[5, 10, 20, 30],\n",
    "                        :c=>[0.1, 1., 10., 100., 1000., 10000.])\n",
    "\n",
    "# For POMCPOW\n",
    "value_estimator = PORollout(rush_policy, PreviousObservationUpdater())\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "pomcpow_dict = Dict(:estimate_value=>[value_estimator, random_value_estimator],\n",
    "                    :tree_queries=>[100000,], \n",
    "                    :max_time=>[1.0,], \n",
    "                    :criterion=>[MaxUCB(0.1), MaxUCB(1.0), MaxUCB(10.), MaxUCB(100.), MaxUCB(1000.)])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [LB_DESPOTSolver=>lbdespot_dict, \n",
    "                UCT_DESPOTSolver=>uctdespot_dict, \n",
    "                POMCPOWSolver=>pomcpow_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bumper Roomba Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=bounds, default_action=rush_policy, tree_in_info=true)\n",
    "solver = UCT_DESPOTSolver(rollout_policy=rollout_policy, tree_in_info=true)\n",
    "# solver = POMCPOWSolver(tree_queries=100000, max_time=1.0, estimate_value=value_estimator, tree_in_info=true)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "makegif(pomdp, planner, belief_updater, filename=\"bumper.gif\", max_steps=100, show_progress=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=bounds, beta=0.2, T_max=60.0, K=100, default_action=rush_policy, tree_in_info=true)\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=rollout_policy, T_max=60.0, m=10, K=100, c=100, tree_in_info=true)\n",
    "# # solver = POMCPOWSolver(tree_queries=1000000, max_time=20.0, criterion=MaxUCB(1000), estimate_value=value_estimator, tree_in_info=true)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# b0 = initialstate_distribution(pomdp)\n",
    "# @time a, info = action_info(planner, b0)\n",
    "# @show info[:record]\n",
    "# D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on Bumper Roomba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 1\n",
    "max_steps = 1\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          belief_updater=belief_updater,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "for i in 1:length(dfs)\n",
    "    CSV.write(\"BumperRoomba$(i).csv\", dfs[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lidar Roomba Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_speed = 2.0\n",
    "speed_interval = 2.0\n",
    "max_turn_rate = 1.0\n",
    "turn_rate_interval = 1.0\n",
    "\n",
    "sensor = Lidar()\n",
    "num_particles = 5000 # number of particles in belief\n",
    "\n",
    "pos_noise_coeff = 0.3\n",
    "ori_noise_coeff = 0.1\n",
    "\n",
    "# POMDP problem\n",
    "action_space = vec([RoombaAct(v, om) for v in 0:speed_interval:max_speed, om in -max_turn_rate:turn_rate_interval:max_turn_rate])\n",
    "pomdp = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(config=2, aspace=action_space))\n",
    "\n",
    "# Belief updater\n",
    "resampler = LidarResampler(num_particles, pomdp, pos_noise_coeff, ori_noise_coeff)\n",
    "belief_updater = BasicParticleFilter(pomdp, resampler, num_particles)\n",
    "\n",
    "# Running policy\n",
    "running_policy = FunctionPolicy() do b\n",
    "    # s = typeof(b) == RoombaState ? b : typeof(b) <: AA228FinalProject.RoombaInitialDistribution ? rand(b) : mean(b)\n",
    "    # The statement is computational inefficient.\n",
    "    s = typeof(b) == RoombaState ? b : rand(b)\n",
    "    # compute the difference between our current heading and one that would\n",
    "    # point to the goal\n",
    "    goal_x, goal_y = get_goal_xy(pomdp)\n",
    "    x,y,th = s[1:3]\n",
    "    ang_to_goal = atan(goal_y - y, goal_x - x)\n",
    "    del_angle = wrap_to_pi(ang_to_goal - th)\n",
    "    \n",
    "    # apply proportional control to compute the turn-rate\n",
    "    Kprop = 1.0\n",
    "    om = Kprop * del_angle\n",
    "    # find the closest option in action space\n",
    "    _,ind = findmin(abs.(om .- (-max_turn_rate:turn_rate_interval:max_turn_rate)))\n",
    "    om = (-max_turn_rate:turn_rate_interval:max_turn_rate)[ind]\n",
    "    # always travel at some fixed velocity\n",
    "    v = max_speed\n",
    "    \n",
    "    return RoombaAct(v, om)\n",
    "end\n",
    "\n",
    "# For LB-DESPOT\n",
    "bounds = IndependentBounds(DefaultPolicyLB(running_policy), 10.0, check_terminal=true)\n",
    "random_bounds = IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp)), 10.0, check_terminal=true)\n",
    "lbdespot_dict = Dict(:default_action=>[running_policy,], \n",
    "                    :bounds=>[bounds, random_bounds],\n",
    "                    :lambda=>[0.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "                    :K=>[100, 300, 500],\n",
    "                    :beta=>[0., 0.1, 1., 10., 100.])\n",
    "\n",
    "# For UCT-DESPOT\n",
    "rollout_policy = running_policy\n",
    "random_rollout_policy = RandomPolicy(pomdp)\n",
    "uctdespot_dict = Dict(:rollout_policy=>[rollout_policy, random_rollout_policy],\n",
    "                        :K=>[100, 300, 500],\n",
    "                        :m=>[5, 10, 20, 30],\n",
    "                        :criterion=>[MaxUCB(0.1), MaxUCB(1.0), MaxUCB(10.), MaxUCB(100.), MaxUCB(1000.)])\n",
    "\n",
    "# For POMCPOW\n",
    "value_estimator = FORollout(running_policy)\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "pomcpow_dict = Dict(:estimate_value=>[value_estimator, random_value_estimator],\n",
    "                    :tree_queries=>[100000,], \n",
    "                    :max_time=>[1.0,], \n",
    "                    :c=>[0.1, 1., 10., 100., 1000., 10000.])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [LB_DESPOTSolver=>lbdespot_dict, \n",
    "                UCT_DESPOTSolver=>uctdespot_dict, \n",
    "                POMCPOWSolver=>pomcpow_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lidar Roomba Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=bounds, default_action=running_policy)\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=rollout_policy)\n",
    "# solver = POMCPOWSolver(tree_queries=100000, max_time=1.0, estimate_value=value_estimator)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# makegif(pomdp, planner, belief_updater, filename=\"lidar.gif\", max_steps=100, show_progress=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=bounds, default_action=running_policy, tree_in_info=true)\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=rollout_policy, tree_in_info=true)\n",
    "# solver = POMCPOWSolver(tree_queries=100000, max_time=1.0, estimate_value=value_estimator, tree_in_info=true)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# b0 = initialstate_distribution(pomdp)\n",
    "# a, info = action_info(planner, b0)\n",
    "# D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on Lidar Roomba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 1\n",
    "max_steps = 1\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          belief_updater=belief_updater,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "for i in 1:length(dfs)\n",
    "    CSV.write(\"LidarRoomba$(i).csv\", dfs[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Lidar Roomba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_speed = 2.0\n",
    "speed_interval = 2.0\n",
    "max_turn_rate = 1.0\n",
    "turn_rate_interval = 1.0\n",
    "\n",
    "cut_points =  exp10.(range(-.5, stop=1.3, length=10))\n",
    "sensor = DiscreteLidar(cut_points)\n",
    "\n",
    "num_particles = 5000 # number of particles in belief\n",
    "\n",
    "pos_noise_coeff = 0.3\n",
    "ori_noise_coeff = 0.1\n",
    "\n",
    "# POMDP problem\n",
    "action_space = vec([RoombaAct(v, om) for v in 0:speed_interval:max_speed, om in -max_turn_rate:turn_rate_interval:max_turn_rate])\n",
    "pomdp = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(config=3, aspace=action_space));\n",
    "\n",
    "# Belief updater\n",
    "resampler = LidarResampler(num_particles, pomdp, pos_noise_coeff, ori_noise_coeff)\n",
    "belief_updater = BasicParticleFilter(pomdp, resampler, num_particles)\n",
    "\n",
    "# Running policy\n",
    "running_policy = FunctionPolicy() do b\n",
    "    # s = typeof(b) == RoombaState ? b : typeof(b) <: AA228FinalProject.RoombaInitialDistribution ? rand(b) : mean(b)\n",
    "    # The statement is computational inefficient.\n",
    "    s = typeof(b) == RoombaState ? b : rand(b)\n",
    "    # compute the difference between our current heading and one that would\n",
    "    # point to the goal\n",
    "    goal_x, goal_y = get_goal_xy(pomdp)\n",
    "    x,y,th = s[1:3]\n",
    "    ang_to_goal = atan(goal_y - y, goal_x - x)\n",
    "    del_angle = wrap_to_pi(ang_to_goal - th)\n",
    "    \n",
    "    # apply proportional control to compute the turn-rate\n",
    "    Kprop = 1.0\n",
    "    om = Kprop * del_angle\n",
    "    # find the closest option in action space\n",
    "    _,ind = findmin(abs.(om .- (-max_turn_rate:turn_rate_interval:max_turn_rate)))\n",
    "    om = (-max_turn_rate:turn_rate_interval:max_turn_rate)[ind]\n",
    "    # always travel at some fixed velocity\n",
    "    v = max_speed\n",
    "    \n",
    "    return RoombaAct(v, om)\n",
    "end\n",
    "\n",
    "# For LB-DESPOT\n",
    "bounds = IndependentBounds(DefaultPolicyLB(running_policy), 10.0, check_terminal=true)\n",
    "random_bounds = IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp)), 10.0, check_terminal=true)\n",
    "lbdespot_dict = Dict(:default_action=>[running_policy,], \n",
    "                    :bounds=>[bounds, random_bounds],\n",
    "                    :lambda=>[0.0, 0.01, 0.1, 1.0],\n",
    "                    :T_max=>[30.0],\n",
    "                    :K=>[100, 500],\n",
    "                    :beta=>[0., 0.5, 1., 5.])\n",
    "\n",
    "# For UCT-DESPOT\n",
    "rollout_policy = running_policy\n",
    "random_rollout_policy = RandomPolicy(pomdp)\n",
    "uctdespot_dict = Dict(:rollout_policy=>[rollout_policy, random_rollout_policy],\n",
    "                        :K=>[100, 500],\n",
    "                        :T_max=>[30.0],\n",
    "                        :m=>[10, 50],\n",
    "                        :c=>[1., 10., 100.])\n",
    "\n",
    "# For POMCPOW\n",
    "value_estimator = FORollout(running_policy)\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "pomcpow_dict = Dict(:estimate_value=>[value_estimator, random_value_estimator],\n",
    "                    :tree_queries=>[100000,], \n",
    "                    :max_time=>[30.0,], \n",
    "                    :criterion=>[MaxUCB(0.1), MaxUCB(1.0), MaxUCB(10.), MaxUCB(100.), MaxUCB(1000.)])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [#LB_DESPOTSolver=>lbdespot_dict, \n",
    "                UCT_DESPOTSolver=>uctdespot_dict, ]\n",
    "                #POMCPOWSolver=>pomcpow_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Lidar Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = LB_DESPOTSolver(bounds=bounds, beta=0.2, K=500, default_action=running_policy)\n",
    "# solver = UCT_DESPOTSolver(m=10, K=100, c=100, T_max=1, rollout_policy=rollout_policy)\n",
    "# solver = POMCPOWSolver(tree_queries=100000, max_time=1.0, estimate_value=value_estimator)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "makegif(pomdp, planner, belief_updater, filename=\"discrete_lidar.gif\", max_steps=100, show_progress=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=bounds, T_max=30.0,lambda=1, beta=0.2, K=300, default_action=running_policy, tree_in_info=true)\n",
    "solver = UCT_DESPOTSolver(rollout_policy=rollout_policy, T_max=10.0, m=30, K=1000, c=1, tree_in_info=true)\n",
    "# solver = POMCPOWSolver(tree_queries=100000, max_time=30.0, criterion=MaxUCB(10), estimate_value=value_estimator, tree_in_info=true)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "b0 = initialstate_distribution(pomdp)\n",
    "a, info = action_info(planner, b0)\n",
    "println(\"number of trials: $(first(info[:record]))\")\n",
    "# @show info[:record]\n",
    "println(\"time for building DESPOT: $(last(info[:record]))\")\n",
    "D3Tree(info[:tree], init_expand=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on Discrete Lidar Roomba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 1\n",
    "max_steps = 1\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          belief_updater=belief_updater,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "CSV.write(\"DiscreteLidarRoomba_LB_DESPOT.csv\", dfs[1])\n",
    "CSV.write(\"DiscreteLidarRoomba_UCT_DESPOT.csv\", dfs[2])\n",
    "CSV.write(\"DiscreteLidarRoomba_POMCPOW.csv\", dfs[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
